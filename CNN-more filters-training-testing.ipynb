{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e821e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries \n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6f9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82be86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefb2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),  #augmentation techniques to artifically increase the sample size\\\n",
    "    transforms.ToTensor(), #PIL image to tensor image with normal pixel range of 0-225 to 0-1\n",
    "    transforms.Normalize([0.5,0.5,0.5],\n",
    "                         [0.5,0.5,0.5]) #changes the range from 0-1 to -1 to 1   \n",
    "                                                      #formula: (x-mean)/standard deviation\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd129f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data (called dataloaders)\n",
    "\n",
    "#paths for training and testing\n",
    "train_path = 'C:\\\\Users\\\\hqi\\\\Documents\\\\seperated data\\\\training data'\n",
    "test_path = 'C:\\\\Users\\\\hqi\\\\Documents\\\\seperated data\\\\test data'\n",
    "#dataloader for training data set\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path, transform = transformer),\n",
    "    batch_size = 64, shuffle = True #shuffle to make sure the model is not biased towards certain categories\n",
    "    #batch size used to be 256\n",
    ")\n",
    "\n",
    "#dataloader for testing data set\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path, transform = transformer),\n",
    "    batch_size = 64, shuffle = True #shuffle to make sure the model is not biased towards certain categories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2507dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch all of the classes \n",
    "root = pathlib.Path(train_path)\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe0eb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benign', 'malignant - melanoma']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7d886b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional neural network class\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    \n",
    "    #specify all of the layers in the network in the constructor\n",
    "    def __init__(self, num_classes = 6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #input shape: (128, 3, 300, 300)\n",
    "        \n",
    "        #apply filter\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        #output size after convolutional filter is applied is represented by this equation:\n",
    "        # ((w-f+2P)/s) +1\n",
    "        #Current Shape: (128, 12, 300, 300)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features = 12)\n",
    "        self.relu1=nn.LeakyReLU()\n",
    "        #Current Shape: (128, 12, 300, 300)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #reduces output height and width by a factor of 2\n",
    "        #Current Shape: (128, 12, 150, 150)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 20, 150, 150)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Current Shape: (128, 20, 150, 150)\n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 32, 150, 150)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features = 32)\n",
    "        self.relu3=nn.LeakyReLU()\n",
    "        #Current Shape: (128, 32, 150, 150)\n",
    "        \n",
    "        \n",
    "        self.conv4=nn.Conv2d(in_channels=32,out_channels=40,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features = 40)\n",
    "        self.relu4=nn.LeakyReLU()\n",
    "        \n",
    "        self.conv5=nn.Conv2d(in_channels=40,out_channels=52,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu5=nn.ReLU()\n",
    "        \n",
    "        self.conv6=nn.Conv2d(in_channels=52,out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu6=nn.ReLU()\n",
    "        \n",
    "        self.conv7=nn.Conv2d(in_channels=64,out_channels=72,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu7=nn.LeakyReLU()\n",
    "        self.bn7 = nn.BatchNorm2d(num_features = 72)\n",
    "        \n",
    "        self.conv8=nn.Conv2d(in_channels=72,out_channels=84,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu8=nn.ReLU()\n",
    "        \n",
    "        self.conv9=nn.Conv2d(in_channels=84,out_channels=92,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu9=nn.ReLU()\n",
    "        \n",
    "        self.conv10=nn.Conv2d(in_channels=92,out_channels=104,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu10=nn.ReLU()\n",
    "        \n",
    "        self.conv11=nn.Conv2d(in_channels=104,out_channels=112,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu11=nn.ReLU()\n",
    "        \n",
    "        self.conv12=nn.Conv2d(in_channels=112,out_channels=124,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu12=nn.ReLU()\n",
    "        self.bn12 = nn.BatchNorm2d(num_features = 124)\n",
    "        \n",
    "        self.conv13=nn.Conv2d(in_channels=124,out_channels= 132,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu13=nn.ReLU()\n",
    "        \n",
    "        self.conv14=nn.Conv2d(in_channels=132,out_channels=144,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu14=nn.ReLU()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 144,out_features=num_classes)\n",
    "       \n",
    "    \n",
    "    \n",
    "    #Feedforward function:\n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "        \n",
    "        output=self.conv4(output)\n",
    "        output=self.bn4(output)\n",
    "        output=self.relu4(output)\n",
    "        \n",
    "        output=self.conv5(output)\n",
    "        output=self.relu5(output)\n",
    "        \n",
    "        output=self.conv6(output)\n",
    "        output=self.relu6(output)\n",
    "        \n",
    "        output=self.conv7(output)\n",
    "        output=self.relu7(output)\n",
    "        output=self.bn7(output)\n",
    "        \n",
    "        output=self.conv8(output)\n",
    "        output=self.relu8(output)\n",
    "        \n",
    "        output=self.conv9(output)\n",
    "        output=self.relu9(output)\n",
    "        \n",
    "        output=self.conv10(output)\n",
    "        output=self.relu10(output)\n",
    "        \n",
    "        output=self.conv11(output)\n",
    "        output=self.relu11(output)\n",
    "        \n",
    "        output=self.conv12(output)\n",
    "        output=self.relu12(output)\n",
    "        output=self.bn12(output)\n",
    "        \n",
    "        output=self.conv13(output)\n",
    "        output=self.relu13(output)\n",
    "        \n",
    "        output=self.conv14(output)\n",
    "        output=self.relu14(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        #shape: (256, 52, 75, 75)\n",
    "        #change shape of matrix to feed into the fc layer\n",
    "        \n",
    "        output = output.view(-1, 144*75*75)\n",
    "        output =self.fc(output)\n",
    "        return output\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad3a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e7123c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes = 6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a14e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "optimizer=Adam(model.parameters(),lr=0.01,weight_decay=0.001)\n",
    "loss_function=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e6d0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f69adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calc size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed3561c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 379\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb804c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hqi\\.conda\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(181.2958) Train Accuracy: 0.6944444444444444 Test Accuracy: 0.7335092348284961\n",
      "Epoch: 1 Train Loss: tensor(1.9024) Train Accuracy: 0.7911111111111111 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 2 Train Loss: tensor(1.3729) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 3 Train Loss: tensor(14.0719) Train Accuracy: 0.6833333333333333 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 4 Train Loss: tensor(0.8482) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 5 Train Loss: tensor(0.8584) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 6 Train Loss: tensor(0.7466) Train Accuracy: 0.8022222222222222 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 7 Train Loss: tensor(7.0551) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 8 Train Loss: tensor(3.9382) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 9 Train Loss: tensor(4.7007) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 10 Train Loss: tensor(0.9672) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 11 Train Loss: tensor(0.8676) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 12 Train Loss: tensor(0.7885) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 13 Train Loss: tensor(0.7311) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 14 Train Loss: tensor(0.6904) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 15 Train Loss: tensor(0.9495) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 16 Train Loss: tensor(13.1180) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 17 Train Loss: tensor(0.5673) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 18 Train Loss: tensor(0.5500) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 19 Train Loss: tensor(0.5673) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 20 Train Loss: tensor(0.5018) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 21 Train Loss: tensor(0.4980) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 22 Train Loss: tensor(0.5018) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 23 Train Loss: tensor(0.5002) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 24 Train Loss: tensor(0.4894) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 25 Train Loss: tensor(0.5030) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 26 Train Loss: tensor(0.4970) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 27 Train Loss: tensor(0.4926) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 28 Train Loss: tensor(0.4931) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 29 Train Loss: tensor(0.5099) Train Accuracy: 0.8066666666666666 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 30 Train Loss: tensor(0.4996) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 31 Train Loss: tensor(0.4923) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 32 Train Loss: tensor(0.5036) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 33 Train Loss: tensor(0.5017) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 34 Train Loss: tensor(0.4987) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 35 Train Loss: tensor(0.4938) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 36 Train Loss: tensor(0.5052) Train Accuracy: 0.8066666666666666 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 37 Train Loss: tensor(0.4920) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 38 Train Loss: tensor(0.5006) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 39 Train Loss: tensor(0.4910) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 40 Train Loss: tensor(0.9359) Train Accuracy: 0.8055555555555556 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 41 Train Loss: tensor(0.5019) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 42 Train Loss: tensor(0.5623) Train Accuracy: 0.8022222222222222 Test Accuracy: 0.7889182058047494\n",
      "Epoch: 43 Train Loss: tensor(0.5027) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 44 Train Loss: tensor(0.4907) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 45 Train Loss: tensor(0.5458) Train Accuracy: 0.8 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 46 Train Loss: tensor(0.5064) Train Accuracy: 0.8066666666666666 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 47 Train Loss: tensor(0.4917) Train Accuracy: 0.8077777777777778 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 48 Train Loss: tensor(0.4918) Train Accuracy: 0.8088888888888889 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 49 Train Loss: tensor(0.5689) Train Accuracy: 0.7944444444444444 Test Accuracy: 0.7994722955145118\n"
     ]
    }
   ],
   "source": [
    "#Training model and saving the most accurate model\n",
    "#Save the model for the epoch that gives the best testing accuracy\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Training on training data set\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #increment for train_loss\n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        #increment for train_accuracy\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    train_accuracy = train_accuracy/train_count\n",
    "    train_loss = train_loss/train_count\n",
    "        \n",
    "    \n",
    "    #Evaluating using testing data set\n",
    "    model.eval()\n",
    "    test_accuracy = 0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        #increment for train_accuracy\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy = test_accuracy/test_count\n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #save best model\n",
    "    \n",
    "    if test_accuracy > best_accuracy:\n",
    "        #save the best model\n",
    "        torch.save(model.state_dict(),'best2_checkpoint.model')\n",
    "        #update the value of best_accuracy\n",
    "        best_accuracy = test_accuracy\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f792d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8e65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7ccac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
