{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e821e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries \n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6f9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82be86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefb2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),  #augmentation techniques to artifically increase the sample size\\\n",
    "    transforms.ToTensor(), #PIL image to tensor image with normal pixel range of 0-225 to 0-1\n",
    "    transforms.Normalize([0.5,0.5,0.5],\n",
    "                         [0.5,0.5,0.5]) #changes the range from 0-1 to -1 to 1   \n",
    "                                                      #formula: (x-mean)/standard deviation\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd129f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data (called dataloaders)\n",
    "\n",
    "#paths for training and testing\n",
    "train_path = 'C:\\\\Users\\\\hqi\\\\Documents\\\\seperated data\\\\training data'\n",
    "test_path = 'C:\\\\Users\\\\hqi\\\\Documents\\\\seperated data\\\\test data'\n",
    "#dataloader for training data set\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path, transform = transformer),\n",
    "    batch_size = 32, shuffle = True #shuffle to make sure the model is not biased towards certain categories\n",
    "    #batch size used to be 256\n",
    ")\n",
    "\n",
    "#dataloader for testing data set\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path, transform = transformer),\n",
    "    batch_size = 16, shuffle = True #shuffle to make sure the model is not biased towards certain categories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2507dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch all of the classes \n",
    "root = pathlib.Path(train_path)\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe0eb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benign', 'malignant - melanoma']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7d886b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional neural network class\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    \n",
    "    #specify all of the layers in the network in the constructor\n",
    "    def __init__(self, num_classes = 6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #input shape: (128, 3, 300, 300)\n",
    "        \n",
    "        #apply filter\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        #output size after convolutional filter is applied is represented by this equation:\n",
    "        # ((w-f+2P)/s) +1\n",
    "        #Current Shape: (128, 12, 300, 300)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features = 12)\n",
    "        self.relu1=nn.LeakyReLU()\n",
    "        #Current Shape: (128, 12, 300, 300)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #reduces output height and width by a factor of 2\n",
    "        #Current Shape: (128, 12, 150, 150)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 20, 150, 150)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Current Shape: (128, 20, 150, 150)\n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 32, 150, 150)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features = 32)\n",
    "        self.relu3=nn.LeakyReLU()\n",
    "        #Current Shape: (128, 32, 150, 150)\n",
    "        \n",
    "        \n",
    "        self.conv4=nn.Conv2d(in_channels=32,out_channels=40,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features = 40)\n",
    "        self.relu4=nn.LeakyReLU()\n",
    "        \n",
    "        self.conv5=nn.Conv2d(in_channels=40,out_channels=52,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu5=nn.ReLU()\n",
    "        \n",
    "        self.conv6=nn.Conv2d(in_channels=52,out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu6=nn.ReLU()\n",
    "        \n",
    "        self.conv7=nn.Conv2d(in_channels=64,out_channels=72,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu7=nn.LeakyReLU()\n",
    "        self.bn7 = nn.BatchNorm2d(num_features = 72)\n",
    "        \n",
    "        self.conv8=nn.Conv2d(in_channels=72,out_channels=84,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 40, 150, 150)\n",
    "        self.relu8=nn.ReLU()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 84,out_features=num_classes)\n",
    "       \n",
    "    \n",
    "    \n",
    "    #Feedforward function:\n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "        \n",
    "        output=self.conv4(output)\n",
    "        output=self.bn4(output)\n",
    "        output=self.relu4(output)\n",
    "        \n",
    "        output=self.conv5(output)\n",
    "        output=self.relu5(output)\n",
    "        \n",
    "        output=self.conv6(output)\n",
    "        output=self.relu6(output)\n",
    "        \n",
    "        output=self.conv7(output)\n",
    "        output=self.relu7(output)\n",
    "        output=self.bn7(output)\n",
    "        \n",
    "        output=self.conv8(output)\n",
    "        output=self.relu8(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        #shape: (256, 52, 75, 75)\n",
    "        #change shape of matrix to feed into the fc layer\n",
    "        \n",
    "        output = output.view(-1, 84*75*75)\n",
    "        output =self.fc(output)\n",
    "        return output\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad3a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e7123c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes = 6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a14e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "optimizer=Adam(model.parameters(),lr=0.0001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e6d0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f69adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calc size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed3561c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 379\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb804c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hqi\\.conda\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(1.4516) Train Accuracy: 0.6877777777777778 Test Accuracy: 0.7968337730870713\n",
      "Epoch: 1 Train Loss: tensor(0.4579) Train Accuracy: 0.8044444444444444 Test Accuracy: 0.8126649076517151\n",
      "Epoch: 2 Train Loss: tensor(0.4669) Train Accuracy: 0.8 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 3 Train Loss: tensor(0.4526) Train Accuracy: 0.82 Test Accuracy: 0.8047493403693932\n",
      "Epoch: 4 Train Loss: tensor(0.4033) Train Accuracy: 0.8388888888888889 Test Accuracy: 0.8047493403693932\n",
      "Epoch: 5 Train Loss: tensor(0.3884) Train Accuracy: 0.8311111111111111 Test Accuracy: 0.7757255936675461\n",
      "Epoch: 6 Train Loss: tensor(0.3798) Train Accuracy: 0.8466666666666667 Test Accuracy: 0.6596306068601583\n",
      "Epoch: 7 Train Loss: tensor(0.4119) Train Accuracy: 0.8311111111111111 Test Accuracy: 0.7994722955145118\n",
      "Epoch: 8 Train Loss: tensor(0.4372) Train Accuracy: 0.8277777777777777 Test Accuracy: 0.7994722955145118\n",
      "Epoch: 9 Train Loss: tensor(0.3191) Train Accuracy: 0.87 Test Accuracy: 0.7651715039577837\n",
      "Epoch: 10 Train Loss: tensor(0.3044) Train Accuracy: 0.8755555555555555 Test Accuracy: 0.8047493403693932\n",
      "Epoch: 11 Train Loss: tensor(0.2603) Train Accuracy: 0.8988888888888888 Test Accuracy: 0.7783641160949868\n",
      "Epoch: 12 Train Loss: tensor(0.2534) Train Accuracy: 0.9066666666666666 Test Accuracy: 0.7941952506596306\n",
      "Epoch: 13 Train Loss: tensor(0.3023) Train Accuracy: 0.8777777777777778 Test Accuracy: 0.7968337730870713\n",
      "Epoch: 14 Train Loss: tensor(0.2453) Train Accuracy: 0.9088888888888889 Test Accuracy: 0.7994722955145118\n",
      "Epoch: 15 Train Loss: tensor(0.2094) Train Accuracy: 0.9144444444444444 Test Accuracy: 0.8047493403693932\n",
      "Epoch: 16 Train Loss: tensor(0.1746) Train Accuracy: 0.9333333333333333 Test Accuracy: 0.7229551451187335\n",
      "Epoch: 17 Train Loss: tensor(0.1556) Train Accuracy: 0.9366666666666666 Test Accuracy: 0.741424802110818\n",
      "Epoch: 18 Train Loss: tensor(0.1216) Train Accuracy: 0.9588888888888889 Test Accuracy: 0.7968337730870713\n",
      "Epoch: 19 Train Loss: tensor(0.1109) Train Accuracy: 0.96 Test Accuracy: 0.8100263852242744\n",
      "Epoch: 20 Train Loss: tensor(0.1431) Train Accuracy: 0.95 Test Accuracy: 0.7730870712401056\n",
      "Epoch: 21 Train Loss: tensor(0.1423) Train Accuracy: 0.9411111111111111 Test Accuracy: 0.7730870712401056\n",
      "Epoch: 22 Train Loss: tensor(0.0635) Train Accuracy: 0.9855555555555555 Test Accuracy: 0.6015831134564644\n",
      "Epoch: 23 Train Loss: tensor(0.1112) Train Accuracy: 0.9555555555555556 Test Accuracy: 0.7097625329815304\n",
      "Epoch: 24 Train Loss: tensor(0.1742) Train Accuracy: 0.94 Test Accuracy: 0.7968337730870713\n",
      "Epoch: 25 Train Loss: tensor(0.0635) Train Accuracy: 0.9844444444444445 Test Accuracy: 0.783641160949868\n",
      "Epoch: 26 Train Loss: tensor(0.0638) Train Accuracy: 0.98 Test Accuracy: 0.7915567282321899\n",
      "Epoch: 27 Train Loss: tensor(0.0321) Train Accuracy: 0.9955555555555555 Test Accuracy: 0.7730870712401056\n",
      "Epoch: 28 Train Loss: tensor(0.0287) Train Accuracy: 0.9944444444444445 Test Accuracy: 0.7440633245382586\n",
      "Epoch: 29 Train Loss: tensor(0.0279) Train Accuracy: 0.9966666666666667 Test Accuracy: 0.8047493403693932\n",
      "Epoch: 30 Train Loss: tensor(0.0190) Train Accuracy: 0.9977777777777778 Test Accuracy: 0.7862796833773087\n",
      "Epoch: 31 Train Loss: tensor(0.0190) Train Accuracy: 0.9977777777777778 Test Accuracy: 0.8153034300791556\n",
      "Epoch: 32 Train Loss: tensor(0.0207) Train Accuracy: 0.9966666666666667 Test Accuracy: 0.6754617414248021\n",
      "Epoch: 33 Train Loss: tensor(0.2064) Train Accuracy: 0.92 Test Accuracy: 0.7941952506596306\n",
      "Epoch: 34 Train Loss: tensor(0.0943) Train Accuracy: 0.9666666666666667 Test Accuracy: 0.712401055408971\n",
      "Epoch: 35 Train Loss: tensor(0.3252) Train Accuracy: 0.8766666666666667 Test Accuracy: 0.7387862796833773\n",
      "Epoch: 36 Train Loss: tensor(0.0995) Train Accuracy: 0.96 Test Accuracy: 0.7282321899736148\n",
      "Epoch: 37 Train Loss: tensor(0.0545) Train Accuracy: 0.9866666666666667 Test Accuracy: 0.7941952506596306\n",
      "Epoch: 38 Train Loss: tensor(0.0282) Train Accuracy: 0.9933333333333333 Test Accuracy: 0.7941952506596306\n",
      "Epoch: 39 Train Loss: tensor(0.0262) Train Accuracy: 0.9944444444444445 Test Accuracy: 0.7810026385224275\n",
      "Epoch: 40 Train Loss: tensor(0.0231) Train Accuracy: 0.9944444444444445 Test Accuracy: 0.7941952506596306\n",
      "Epoch: 41 Train Loss: tensor(0.0229) Train Accuracy: 0.9933333333333333 Test Accuracy: 0.783641160949868\n",
      "Epoch: 42 Train Loss: tensor(0.0113) Train Accuracy: 0.9977777777777778 Test Accuracy: 0.7941952506596306\n",
      "Epoch: 43 Train Loss: tensor(0.0087) Train Accuracy: 1.0 Test Accuracy: 0.7994722955145118\n",
      "Epoch: 44 Train Loss: tensor(0.0103) Train Accuracy: 0.9977777777777778 Test Accuracy: 0.7704485488126649\n",
      "Epoch: 45 Train Loss: tensor(0.0142) Train Accuracy: 0.9955555555555555 Test Accuracy: 0.7994722955145118\n",
      "Epoch: 46 Train Loss: tensor(0.0110) Train Accuracy: 0.9977777777777778 Test Accuracy: 0.8153034300791556\n",
      "Epoch: 47 Train Loss: tensor(0.0171) Train Accuracy: 0.9977777777777778 Test Accuracy: 0.7941952506596306\n",
      "Epoch: 48 Train Loss: tensor(0.0155) Train Accuracy: 0.9977777777777778 Test Accuracy: 0.783641160949868\n",
      "Epoch: 49 Train Loss: tensor(0.0132) Train Accuracy: 0.9977777777777778 Test Accuracy: 0.6992084432717678\n"
     ]
    }
   ],
   "source": [
    "#Training model and saving the most accurate model\n",
    "#Save the model for the epoch that gives the best testing accuracy\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Training on training data set\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #increment for train_loss\n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        #increment for train_accuracy\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    train_accuracy = train_accuracy/train_count\n",
    "    train_loss = train_loss/train_count\n",
    "        \n",
    "    \n",
    "    #Evaluating using testing data set\n",
    "    model.eval()\n",
    "    test_accuracy = 0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        #increment for train_accuracy\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy = test_accuracy/test_count\n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #save best model\n",
    "    \n",
    "    if test_accuracy > best_accuracy:\n",
    "        #save the best model\n",
    "        torch.save(model.state_dict(),'best2_checkpoint.model')\n",
    "        #update the value of best_accuracy\n",
    "        best_accuracy = test_accuracy\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f792d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8e65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7ccac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
