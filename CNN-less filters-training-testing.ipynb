{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e821e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries \n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6f9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82be86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefb2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),  #augmentation techniques to artifically increase the sample size\\\n",
    "    transforms.ToTensor(), #PIL image to tensor image with normal pixel range of 0-225 to 0-1\n",
    "    transforms.Normalize([0.5,0.5,0.5],\n",
    "                         [0.5,0.5,0.5]) #changes the range from 0-1 to -1 to 1   \n",
    "                                                      #formula: (x-mean)/standard deviation\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd129f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data (called dataloaders)\n",
    "\n",
    "#paths for training and testing\n",
    "train_path = 'C:\\\\Users\\\\hqi\\\\Documents\\\\seperated data\\\\training data'\n",
    "test_path = 'C:\\\\Users\\\\hqi\\\\Documents\\\\seperated data\\\\test data'\n",
    "#dataloader for training data set\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path, transform = transformer),\n",
    "    batch_size = 64, shuffle = True #shuffle to make sure the model is not biased towards certain categories\n",
    "    #batch size used to be 256\n",
    ")\n",
    "\n",
    "#dataloader for testing data set\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path, transform = transformer),\n",
    "    batch_size = 32, shuffle = True #shuffle to make sure the model is not biased towards certain categories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2507dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch all of the classes \n",
    "root = pathlib.Path(train_path)\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe0eb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benign', 'malignant - melanoma']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7d886b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional neural network class\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    \n",
    "    #specify all of the layers in the network in the constructor\n",
    "    def __init__(self, num_classes = 6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #input shape: (128, 3, 300, 300)\n",
    "        \n",
    "        #apply filter\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #output size after convolutional filter is applied is represented by this equation:\n",
    "        # ((w-f+2P)/s) +1\n",
    "        #Current Shape: (128, 12, 300, 300)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features = 12)\n",
    "        self.relu1=nn.LeakyReLU()\n",
    "        #Current Shape: (128, 12, 300, 300)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Current Shape: (128, 20, 150, 150)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Current Shape: (128, 20, 150, 150)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=150 * 150 * 20,out_features=num_classes)\n",
    "       \n",
    "    \n",
    "    \n",
    "    #Feedforward function:\n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        #shape: (256, 52, 75, 75)\n",
    "        #change shape of matrix to feed into the fc layer\n",
    "        \n",
    "        output = output.view(-1, 20*150*150)\n",
    "        output =self.fc(output)\n",
    "        return output\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad3a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e7123c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes = 6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a14e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "optimizer=Adam(model.parameters(),lr=0.01,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e6d0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f69adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calc size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed3561c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 379\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb804c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(45.9762) Train Accuracy: 0.64 Test Accuracy: 0.8073878627968337\n",
      "Epoch: 1 Train Loss: tensor(1.3139) Train Accuracy: 0.7833333333333333 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 2 Train Loss: tensor(0.8406) Train Accuracy: 0.7588888888888888 Test Accuracy: 0.7994722955145118\n",
      "Epoch: 3 Train Loss: tensor(0.7748) Train Accuracy: 0.7788888888888889 Test Accuracy: 0.7783641160949868\n",
      "Epoch: 4 Train Loss: tensor(0.7197) Train Accuracy: 0.8088888888888889 Test Accuracy: 0.7862796833773087\n",
      "Epoch: 5 Train Loss: tensor(0.6849) Train Accuracy: 0.7966666666666666 Test Accuracy: 0.8047493403693932\n",
      "Epoch: 6 Train Loss: tensor(0.6034) Train Accuracy: 0.8055555555555556 Test Accuracy: 0.7968337730870713\n",
      "Epoch: 7 Train Loss: tensor(0.6229) Train Accuracy: 0.8122222222222222 Test Accuracy: 0.7941952506596306\n",
      "Epoch: 8 Train Loss: tensor(0.5537) Train Accuracy: 0.8022222222222222 Test Accuracy: 0.7968337730870713\n",
      "Epoch: 9 Train Loss: tensor(0.4895) Train Accuracy: 0.8244444444444444 Test Accuracy: 0.7810026385224275\n",
      "Epoch: 10 Train Loss: tensor(0.4849) Train Accuracy: 0.8233333333333334 Test Accuracy: 0.7704485488126649\n",
      "Epoch: 11 Train Loss: tensor(0.4589) Train Accuracy: 0.8222222222222222 Test Accuracy: 0.7862796833773087\n",
      "Epoch: 12 Train Loss: tensor(0.4406) Train Accuracy: 0.8311111111111111 Test Accuracy: 0.7783641160949868\n",
      "Epoch: 13 Train Loss: tensor(0.4225) Train Accuracy: 0.8388888888888889 Test Accuracy: 0.7757255936675461\n",
      "Epoch: 14 Train Loss: tensor(0.3923) Train Accuracy: 0.8511111111111112 Test Accuracy: 0.6992084432717678\n",
      "Epoch: 15 Train Loss: tensor(0.5133) Train Accuracy: 0.7988888888888889 Test Accuracy: 0.7757255936675461\n",
      "Epoch: 16 Train Loss: tensor(0.4420) Train Accuracy: 0.8388888888888889 Test Accuracy: 0.8021108179419525\n",
      "Epoch: 17 Train Loss: tensor(0.3918) Train Accuracy: 0.8555555555555555 Test Accuracy: 0.7757255936675461\n",
      "Epoch: 18 Train Loss: tensor(0.3781) Train Accuracy: 0.8611111111111112 Test Accuracy: 0.7862796833773087\n",
      "Epoch: 19 Train Loss: tensor(0.3762) Train Accuracy: 0.8555555555555555 Test Accuracy: 0.762532981530343\n",
      "Epoch: 20 Train Loss: tensor(0.3369) Train Accuracy: 0.8744444444444445 Test Accuracy: 0.7678100263852242\n",
      "Epoch: 21 Train Loss: tensor(0.3353) Train Accuracy: 0.8877777777777778 Test Accuracy: 0.762532981530343\n",
      "Epoch: 22 Train Loss: tensor(0.3275) Train Accuracy: 0.8811111111111111 Test Accuracy: 0.7704485488126649\n",
      "Epoch: 23 Train Loss: tensor(0.3239) Train Accuracy: 0.8811111111111111 Test Accuracy: 0.7651715039577837\n",
      "Epoch: 24 Train Loss: tensor(0.3209) Train Accuracy: 0.8811111111111111 Test Accuracy: 0.7730870712401056\n",
      "Epoch: 25 Train Loss: tensor(0.2869) Train Accuracy: 0.89 Test Accuracy: 0.7783641160949868\n",
      "Epoch: 26 Train Loss: tensor(0.2630) Train Accuracy: 0.8955555555555555 Test Accuracy: 0.7862796833773087\n",
      "Epoch: 27 Train Loss: tensor(0.2818) Train Accuracy: 0.8966666666666666 Test Accuracy: 0.762532981530343\n",
      "Epoch: 28 Train Loss: tensor(0.2951) Train Accuracy: 0.8888888888888888 Test Accuracy: 0.7361477572559367\n",
      "Epoch: 29 Train Loss: tensor(0.2471) Train Accuracy: 0.9122222222222223 Test Accuracy: 0.7783641160949868\n",
      "Epoch: 30 Train Loss: tensor(0.2994) Train Accuracy: 0.89 Test Accuracy: 0.741424802110818\n",
      "Epoch: 31 Train Loss: tensor(0.3024) Train Accuracy: 0.8822222222222222 Test Accuracy: 0.7783641160949868\n",
      "Epoch: 32 Train Loss: tensor(0.2845) Train Accuracy: 0.8911111111111111 Test Accuracy: 0.7335092348284961\n",
      "Epoch: 33 Train Loss: tensor(0.2502) Train Accuracy: 0.9033333333333333 Test Accuracy: 0.7493403693931399\n",
      "Epoch: 34 Train Loss: tensor(0.2503) Train Accuracy: 0.9022222222222223 Test Accuracy: 0.7546174142480211\n",
      "Epoch: 35 Train Loss: tensor(0.2701) Train Accuracy: 0.9066666666666666 Test Accuracy: 0.7572559366754618\n",
      "Epoch: 36 Train Loss: tensor(0.2653) Train Accuracy: 0.9044444444444445 Test Accuracy: 0.7493403693931399\n",
      "Epoch: 37 Train Loss: tensor(0.2984) Train Accuracy: 0.8822222222222222 Test Accuracy: 0.7255936675461742\n",
      "Epoch: 38 Train Loss: tensor(0.2832) Train Accuracy: 0.8966666666666666 Test Accuracy: 0.741424802110818\n",
      "Epoch: 39 Train Loss: tensor(0.2708) Train Accuracy: 0.91 Test Accuracy: 0.7651715039577837\n",
      "Epoch: 40 Train Loss: tensor(0.2663) Train Accuracy: 0.9111111111111111 Test Accuracy: 0.7335092348284961\n",
      "Epoch: 41 Train Loss: tensor(0.2698) Train Accuracy: 0.9022222222222223 Test Accuracy: 0.7678100263852242\n",
      "Epoch: 42 Train Loss: tensor(0.2488) Train Accuracy: 0.9133333333333333 Test Accuracy: 0.7598944591029023\n",
      "Epoch: 43 Train Loss: tensor(0.2367) Train Accuracy: 0.9233333333333333 Test Accuracy: 0.7678100263852242\n",
      "Epoch: 44 Train Loss: tensor(0.2014) Train Accuracy: 0.9244444444444444 Test Accuracy: 0.762532981530343\n",
      "Epoch: 45 Train Loss: tensor(0.2113) Train Accuracy: 0.92 Test Accuracy: 0.741424802110818\n",
      "Epoch: 46 Train Loss: tensor(0.2476) Train Accuracy: 0.9022222222222223 Test Accuracy: 0.7467018469656992\n",
      "Epoch: 47 Train Loss: tensor(0.1941) Train Accuracy: 0.9333333333333333 Test Accuracy: 0.7308707124010554\n",
      "Epoch: 48 Train Loss: tensor(0.1760) Train Accuracy: 0.9377777777777778 Test Accuracy: 0.7757255936675461\n",
      "Epoch: 49 Train Loss: tensor(0.2254) Train Accuracy: 0.9155555555555556 Test Accuracy: 0.7335092348284961\n"
     ]
    }
   ],
   "source": [
    "#Training model and saving the most accurate model\n",
    "#Save the model for the epoch that gives the best testing accuracy\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Training on training data set\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #increment for train_loss\n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        #increment for train_accuracy\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    train_accuracy = train_accuracy/train_count\n",
    "    train_loss = train_loss/train_count\n",
    "        \n",
    "    \n",
    "    #Evaluating using testing data set\n",
    "    model.eval()\n",
    "    test_accuracy = 0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        #increment for train_accuracy\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy = test_accuracy/test_count\n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #save best model\n",
    "    \n",
    "    if test_accuracy > best_accuracy:\n",
    "        #save the best model\n",
    "        torch.save(model.state_dict(),'best_few_filters_checkpoint.model')\n",
    "        #update the value of best_accuracy\n",
    "        best_accuracy = test_accuracy\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f792d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8e65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
